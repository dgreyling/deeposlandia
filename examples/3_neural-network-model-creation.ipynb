{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, simple neural networks will be created thanks to `deeposlandia` modules. Some standard neural network architectures will be explored whether it be for feature detection or for semantic segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before to begin, some modules are imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeposlandia import feature_detection, semantic_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionnally, we define some basic variable to generalize the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "NB_CHANNELS = 3\n",
    "NB_LABELS = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seminal cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, two basic models may be generated as an illustration, the former for solving feature detection problems, the latter for solving semantic segmentation problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dedicated literature, a lot of neural networks exist in order to address the feature detection problem. Basically, two kinds of layer are unmissable:\n",
    "- convolutional layers, often coming with pooling layers\n",
    "- fully-connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first proposed architecture uses these layers. It comes as follows:\n",
    "- 1 convolutional layer (number of filters: `16`, kernel size: `7*7`), followed by a max-pooling layer (pool size: `2*2`);\n",
    "- 1 convolutional layer (number of filters: `32`, kernel size: `5*5`), followed by a max-pooling layer (pool size: `2*2`);\n",
    "- 1 convolutional layer (number of filters: `64`, kernel size: `3*3`), followed by a max-pooling layer (pool size: `2*2`);\n",
    "- 1 fully-connected layer (depth: `512`);\n",
    "- 1 fully-connected layer (depth: `nb_labels`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build such a network, an instance of `FeatureDetectionNetwork` is created. The output of this object is a tensor of shape `BATCH_SIZE*NB_LABELS`, each image in the batch being characterized by `NB_LABELS` boolean values (`1` if the label is on the picture, `0` otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdn = feature_detection.FeatureDetectionNetwork(\"featdet\",\n",
    "                                                image_size=IMG_SIZE,\n",
    "                                                nb_channels=NB_CHANNELS,\n",
    "                                                nb_labels=NB_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(13)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdn.Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the network is available, a `keras.models.Model` is instance with the network input and output layers. This is the object which will be fitted with a training generator, as defined in [another notebook](./2_generator-creation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdm = Model(fdn.X, fdn.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 13)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_conv (Conv2D)          (None, 128, 128, 16)      2368      \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 128, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv1_activation (Activation (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2_conv (Conv2D)          (None, 64, 64, 32)        12832     \n",
      "_________________________________________________________________\n",
      "conv2_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2_activation (Activation (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3_conv (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv3_bn (BatchNormalization (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv3_activation (Activation (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten1 (Flatten)           (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "fc1_fc (Dense)               (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "fc1_bn (BatchNormalization)  (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "fc1_activation (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1_dropout (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output_fc (Dense)            (None, 13)                6669      \n",
      "_________________________________________________________________\n",
      "output_activation (Activatio (None, 13)                0         \n",
      "=================================================================\n",
      "Total params: 8,431,981\n",
      "Trainable params: 8,430,733\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fdm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a remark, we can take advantage of [Keras functional API](https://keras.io/models/model/). The `summary` method provides the amount of parameters in the model, as well as the model architecture. Here we have a model with more than 8,4 millions of parameters (mostly due to the first fully-connected layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of semantic segmentation, the point is to provide an output image with a size equivalent to the input image size. The fully-connected layers are far less important, on the opposite of convolutional layers. The key here is the design of a mechanism that ensures decoding process, as standard convolutional layers (or pooling layers) ensure encoding process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic network designed for solving semantic segmentation here is as follows. It uses [\"transposed\" convolution layers](http://www.matthewzeiler.com/wp-content/uploads/2017/07/cvpr2010.pdf):\n",
    "- 1 convolutional layer (number of filters: `32`, kernel size: `3*3`), followed by a max-pooling layer (pool size: `2*2`);\n",
    "- 1 convolutional layer (number of filters: `64`, kernel size: `3*3`), followed by a max-pooling layer (pool size: `2*2`);\n",
    "- 1 convolutional layer (number of filters: `128`, kernel size: `3*3`), followed by a max-pooling layer (pool size: `2*2`);\n",
    "- 1 transposed convolution layer (number of filters: `128`, strides: `2`, kernel size: `3*3`);\n",
    "- 1 transposed convolution layer (number of filters: `64`, strides: `2`, kernel size: `3*3`);\n",
    "- 1 transposed convolution layer (number of filters: `32`, strides: `2`, kernel size: `3*3`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously, a network is created with the instanciation of the accurate object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssn = semantic_segmentation.SemanticSegmentationNetwork(\"semseg\",\n",
    "                                                        image_size=IMG_SIZE,\n",
    "                                                        nb_channels=NB_CHANNELS,\n",
    "                                                        nb_labels=NB_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(13)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssn.Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the output layer shape is quite more complex, as one expects to get a classification answer for each pixel (the three first dimension are relative to the batch, the image width and the image height). This classification information is located in the last dimension: that is an array of `NB_LABELS` boolean values, notifying to which label each pixel corresponds to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously, a Keras model is built starting from the network architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm = Model(ssn.X, ssn.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 128, 128, 13)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_conv (Conv2D)          (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_activation (Activation (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2_conv (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2_bn (BatchNormalization (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2_activation (Activation (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3_conv (Conv2D)          (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv3_bn (BatchNormalization (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv3_activation (Activation (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "trconv1_transconv (Conv2DTra (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "trconv1_bn (BatchNormalizati (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "trconv1_activation (Activati (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "trconv2_transconv (Conv2DTra (None, 64, 64, 64)        73792     \n",
      "_________________________________________________________________\n",
      "trconv2_bn (BatchNormalizati (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "trconv2_activation (Activati (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "trconv3_transconv (Conv2DTra (None, 128, 128, 32)      18464     \n",
      "_________________________________________________________________\n",
      "trconv3_bn (BatchNormalizati (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "trconv3_activation (Activati (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "output_trconv (Conv2DTranspo (None, 128, 128, 13)      1677      \n",
      "_________________________________________________________________\n",
      "output_activation (Activatio (None, 128, 128, 13)      0         \n",
      "=================================================================\n",
      "Total params: 336,557\n",
      "Trainable params: 335,661\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ssm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of parameter here is largely smaller (~330k), as there is not any fully-connected layer in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more complex cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section are dedicated to alternative architectures that are considered in this framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature detection, we get:\n",
    "- [VGG](https://arxiv.org/pdf/1409.1556.pdf)\n",
    "- [Inception](https://arxiv.org/pdf/1512.00567v3.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For semantic segmentation, we get:\n",
    "- [Unet](https://arxiv.org/pdf/1505.04597.pdf)\n",
    "- [Dilated network](https://arxiv.org/abs/1511.07122)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc1_fc (Dense)               (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "fc1_bn (BatchNormalization)  (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "fc1_activation (Activation)  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1_dropout (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2_fc (Dense)               (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "fc2_bn (BatchNormalization)  (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "fc2_activation (Activation)  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2_dropout (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "output_fc (Dense)            (None, 13)                13325     \n",
      "_________________________________________________________________\n",
      "output_activation (Activatio (None, 13)                0         \n",
      "=================================================================\n",
      "Total params: 24,175,437\n",
      "Trainable params: 24,171,341\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = feature_detection.FeatureDetectionNetwork(\"vgg\",\n",
    "                                                image_size=IMG_SIZE,\n",
    "                                                nb_channels=NB_CHANNELS,\n",
    "                                                nb_labels=NB_LABELS,\n",
    "                                                architecture=\"vgg16\")\n",
    "vgg_model = Model(vgg.X, vgg.Y)\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This architecture is one of the more performing one for feature detection, however it is at the cost of a high number of parameters. In this little example, we get more than 24 millions of parameters (~3 times more)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_conv (Conv2D)          (None, 128, 128, 16)      2368      \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 128, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv1_activation (Activation (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2_conv (Conv2D)          (None, 64, 64, 32)        12832     \n",
      "_________________________________________________________________\n",
      "conv2_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2_activation (Activation (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3_conv (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv3_bn (BatchNormalization (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv3_activation (Activation (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten1 (Flatten)           (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "fc1_fc (Dense)               (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "fc1_bn (BatchNormalization)  (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "fc1_activation (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1_dropout (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output_fc (Dense)            (None, 13)                6669      \n",
      "_________________________________________________________________\n",
      "output_activation (Activatio (None, 13)                0         \n",
      "=================================================================\n",
      "Total params: 8,431,981\n",
      "Trainable params: 8,430,733\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inc = feature_detection.FeatureDetectionNetwork(\"inc\",\n",
    "                                                image_size=IMG_SIZE,\n",
    "                                                nb_channels=NB_CHANNELS,\n",
    "                                                nb_labels=NB_LABELS,\n",
    "                                                architecture=\"inception\")\n",
    "inc_model = Model(inc.X, inc.Y)\n",
    "inc_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its advantage is that it can be less resource-consuming than VGG network, even if last developments arise with bigger Inception networks. However, this architecture is known as the best alternative in the feature detection state-of-the-art."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_conv (Conv2D)          (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_activation (Activation (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2_conv (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2_bn (BatchNormalization (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2_activation (Activation (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3_conv (Conv2D)          (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv3_bn (BatchNormalization (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv3_activation (Activation (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "trconv1_transconv (Conv2DTra (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "trconv1_bn (BatchNormalizati (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "trconv1_activation (Activati (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "trconv2_transconv (Conv2DTra (None, 64, 64, 64)        73792     \n",
      "_________________________________________________________________\n",
      "trconv2_bn (BatchNormalizati (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "trconv2_activation (Activati (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "trconv3_transconv (Conv2DTra (None, 128, 128, 32)      18464     \n",
      "_________________________________________________________________\n",
      "trconv3_bn (BatchNormalizati (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "trconv3_activation (Activati (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "output_trconv (Conv2DTranspo (None, 128, 128, 13)      1677      \n",
      "_________________________________________________________________\n",
      "output_activation (Activatio (None, 128, 128, 13)      0         \n",
      "=================================================================\n",
      "Total params: 336,557\n",
      "Trainable params: 335,661\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet = semantic_segmentation.SemanticSegmentationNetwork(\"unet\",\n",
    "                                                         image_size=IMG_SIZE,\n",
    "                                                         nb_channels=NB_CHANNELS,\n",
    "                                                         nb_labels=NB_LABELS,\n",
    "                                                         architecture=\"unet\")\n",
    "unet_model = Model(unet.X, unet.Y)\n",
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unet networks are similar to simple network, in the sense that they are composed of an encoding part and a decoding part. However, a major difference exists, as encoding layers are linked to decoding layers at comparable steps. The decoding side is then composed of concatenations between encoding layer result and transposed convolution of previous layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilated network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_conv (Conv2D)          (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_activation (Activation (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2_conv (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2_bn (BatchNormalization (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2_activation (Activation (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3_conv (Conv2D)          (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv3_bn (BatchNormalization (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv3_activation (Activation (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "trconv1_transconv (Conv2DTra (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "trconv1_bn (BatchNormalizati (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "trconv1_activation (Activati (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "trconv2_transconv (Conv2DTra (None, 64, 64, 64)        73792     \n",
      "_________________________________________________________________\n",
      "trconv2_bn (BatchNormalizati (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "trconv2_activation (Activati (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "trconv3_transconv (Conv2DTra (None, 128, 128, 32)      18464     \n",
      "_________________________________________________________________\n",
      "trconv3_bn (BatchNormalizati (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "trconv3_activation (Activati (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "output_trconv (Conv2DTranspo (None, 128, 128, 13)      1677      \n",
      "_________________________________________________________________\n",
      "output_activation (Activatio (None, 128, 128, 13)      0         \n",
      "=================================================================\n",
      "Total params: 336,557\n",
      "Trainable params: 335,661\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dil = semantic_segmentation.SemanticSegmentationNetwork(\"dilated\",\n",
    "                                                        image_size=IMG_SIZE,\n",
    "                                                        nb_channels=NB_CHANNELS,\n",
    "                                                        nb_labels=NB_LABELS,\n",
    "                                                        architecture=\"dilated\")\n",
    "dil_model = Model(dil.X, dil.Y)\n",
    "dil_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last developed network makes a large use of dilated convolutions. It is composed of three main phases:\n",
    "- an encoding step largely inspired from VGG network (without final fully-connected layers);\n",
    "- a context exploration step, which consists in a row of convolutional layers with different dilation rate, in order to investigate on pixel more or less close from the pixel of interest;\n",
    "- a decoding step composed of classic transposed convolution layers, to go back to the input image size (this phase is absent from original paper, and has been added here)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
